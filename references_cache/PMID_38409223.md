---
reference_id: "PMID:38409223"
title: "scGPT: toward building a foundation model for single-cell multi-omics using generative AI."
authors:
- Cui H
- Wang C
- Maan H
- Pang K
- Luo F
- Duan N
- Wang B
journal: Nat Methods
year: '2024'
doi: 10.1038/s41592-024-02201-0
content_type: abstract_only
---

# scGPT: toward building a foundation model for single-cell multi-omics using generative AI.
**Authors:** Cui H, Wang C, Maan H, Pang K, Luo F, Duan N, Wang B
**Journal:** Nat Methods (2024)
**DOI:** [10.1038/s41592-024-02201-0](https://doi.org/10.1038/s41592-024-02201-0)

## Content

1. Nat Methods. 2024 Aug;21(8):1470-1480. doi: 10.1038/s41592-024-02201-0. Epub 
2024 Feb 26.

scGPT: toward building a foundation model for single-cell multi-omics using 
generative AI.

Cui H(#)(1)(2)(3), Wang C(#)(1)(2)(3), Maan H(1)(3)(4), Pang K(2)(3), Luo 
F(2)(3), Duan N(5), Wang B(6)(7)(8)(9)(10)(11).

Author information:
(1)Peter Munk Cardiac Centre, University Health Network, Toronto, Ontartio, 
Canada.
(2)Department of Computer Science, University of Toronto, Toronto, Ontario, 
Canada.
(3)Vector Institute, Toronto, Ontario, Canada.
(4)Department of Medical Biophysics, University of Toronto, Toronto, Ontario, 
Canada.
(5)Microsoft Research, Redmond, WA, USA.
(6)Peter Munk Cardiac Centre, University Health Network, Toronto, Ontartio, 
Canada. bowang@vectorinstitute.ai.
(7)Department of Computer Science, University of Toronto, Toronto, Ontario, 
Canada. bowang@vectorinstitute.ai.
(8)Vector Institute, Toronto, Ontario, Canada. bowang@vectorinstitute.ai.
(9)Department of Medical Biophysics, University of Toronto, Toronto, Ontario, 
Canada. bowang@vectorinstitute.ai.
(10)Department of Laboratory Medicine and Pathobiology, University of Toronto, 
Toronto, Ontario, Canada. bowang@vectorinstitute.ai.
(11)AI Hub, University Health Network, Toronto, Ontario, Canada. 
bowang@vectorinstitute.ai.
(#)Contributed equally

Generative pretrained models have achieved remarkable success in various domains 
such as language and computer vision. Specifically, the combination of 
large-scale diverse datasets and pretrained transformers has emerged as a 
promising approach for developing foundation models. Drawing parallels between 
language and cellular biology (in which texts comprise words; similarly, cells 
are defined by genes), our study probes the applicability of foundation models 
to advance cellular biology and genetic research. Using burgeoning single-cell 
sequencing data, we have constructed a foundation model for single-cell biology, 
scGPT, based on a generative pretrained transformer across a repository of over 
33 million cells. Our findings illustrate that scGPT effectively distills 
critical biological insights concerning genes and cells. Through further 
adaptation of transfer learning, scGPT can be optimized to achieve superior 
performance across diverse downstream applications. This includes tasks such as 
cell type annotation, multi-batch integration, multi-omic integration, 
perturbation response prediction and gene network inference.

Â© 2024. The Author(s), under exclusive licence to Springer Nature America, Inc.

DOI: 10.1038/s41592-024-02201-0
PMID: 38409223 [Indexed for MEDLINE]